{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies et du modele d'entrainement puis de la fonction d'extraction du texte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pdfplumber\n",
    "from spacy.training.example import Example\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text(encoding='utf-8')  # Spécifie l'encodage\n",
    "    return text\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    phone_numbers = re.findall(r'\\b\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}\\b', text)\n",
    "    return phone_numbers\n",
    "\n",
    "def extract_emails(text):\n",
    "    emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    return emails\n",
    "def extract_languages(text):\n",
    "    languages = re.findall(r'\\b(?:français|anglais|espagnol|allemand)\\b(?:\\s(?:A|B|C)\\d)?', text, flags=re.IGNORECASE)\n",
    "    return languages\n",
    "\n",
    "def extract_date_ranges(text):\n",
    "    date_ranges = []\n",
    "    # Expressions régulières pour les séparateurs '-' et '_'\n",
    "    regex_dash = r'(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}\\s-\\s(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}'\n",
    "    regex_underscore = r'(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}\\s_\\s(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}'\n",
    "    regex_underscore_witout_space = r'(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}_(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}'\n",
    "    regex_dash_witout_space = r'(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}-(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}'\n",
    "    date_rangeM =r'(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4}\\s–\\s(?:Maintenant|(?:Janvier|Février|Mars|Avril|Mai|Juin|Juillet|Août|Septembre|Octobre|Novembre|Décembre)\\s\\d{4})'\n",
    "\n",
    "    # Recherche des plages de dates dans le texte\n",
    "    matches_dash = re.findall(regex_dash, text)\n",
    "    matches_underscore = re.findall(regex_underscore, text)\n",
    "    matches_underscore_witout_space = re.findall(regex_underscore_witout_space, text)\n",
    "    matches_dash_witout_space = re.findall(regex_dash_witout_space, text)\n",
    "    matches_date_rangeM = re.findall(date_rangeM, text)\n",
    "    # Ajout des résultats des deux expressions régulières dans un seul tableau\n",
    "    date_ranges.extend(matches_underscore_witout_space)\n",
    "    date_ranges.extend(matches_underscore)\n",
    "    date_ranges.extend(matches_dash)\n",
    "    date_ranges.extend(matches_dash_witout_space)\n",
    "    date_ranges.extend(matches_date_rangeM)\n",
    "\n",
    "    return date_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du texte extrait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mélisande Yung\n",
      "Responsable marketing\n",
      "3 ans chez Rakuten, en tant que chef de projet marketing e-commerce et assistante\n",
      "marketing (secteur mode et beauté). J’y ai augmenté le nombre de visiteurs de 30% et passé\n",
      "le taux de conversion de 1,8% à 4,2%. Maîtrisant les supports du marketing digital, réseaux\n",
      "sociaux et contenu (CMS et Google Analytics), je peux permettre à votre boutique de mode\n",
      "en ligne d’exploser en nombre de visiteurs et d’acheteur\n",
      "Experiences professionnelles\n",
      "Décembre 2017 – Maintenant\n",
      "Rakuten France, Paris\n",
      "Chef de projet marketing e-commerce (secteur mode et beauté)\n",
      "Coordonnées\n",
      "• Développer le trafic vers la boutique en ligne Mode et Beauté (+30% trafic).\n",
      "• Augmenter le taux de conversion (+133%) et réduire le taux de rebond (-85%).\n",
      "• Superviser les équipes marketing et Interface Utilisateur pour améliorer le site et le\n",
      "Adresse\n",
      "processus d’achat.\n",
      "• Planifier le budget des stratégies et projets webmarketing.\n",
      "15, boulevard Amiral\n",
      "Courbet\n",
      "Novembre 2016 – Décembre 2017\n",
      "Rakuten France, Paris\n",
      "Numéro de téléphone\n",
      "Assistante marketing digital\n",
      "0485435365\n",
      "• Gérer les communications entre les équipes produit, informatique et contenu.\n",
      "• Planifier et réaliser les campagnes marketing réseaux sociaux (+200 000 fans sur\n",
      "Adresse électronique\n",
      "Facebook, taux d’engagement passé de 1,2% à 2,9%).\n",
      "nom@gmail.com\n",
      "• Analyser la base de données clients pour optimiser les courriels automatiques.\n",
      "Avril 2016 – Septembre 2016\n",
      "Langues\n",
      "E-co Solutions, Strasbourg\n",
      "Assistante webmarketing (stage de 6 mois)\n",
      "• Conduire une étude sur la satisfaction des internautes concernant leurs expériences\n",
      "Français\n",
      "e-commerce.\n",
      "• Évaluer les points faibles relevés pour nos clients et proposer des solutions. Anglais (Niveau B2)\n",
      "• Planifier leurs stratégies marketing digital et réaliser les devis.\n",
      "Formation\n",
      "Centre d’intérêt\n",
      "Septembre 2014 – Septembre 2016\n",
      "MSc Digital Marketing (master)\n",
      "Skema Business School, Sophia Antipolis Football\n",
      "Course\n",
      "Septembre 2013 - Juin 2014\n",
      "Licence Pro e-commerce et marketing numérique\n",
      "Automobile Camping\n",
      "IUT Aix-Marseille, Aix-en-Provence\n",
      "Compétences\n",
      "• Stratégie webmarketing et e-commerce\n",
      "• Planification de budget et de projet\n",
      "• Optimisation de boutique en ligne (taux de conversion, de visites…)\n",
      "• Qualités de meneuse d’équipe\n",
      "• Communication\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"CV-14.pdf\"  # Remplacez ceci par votre chemin\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code pour entrainer l'analyseur de PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 31.571430206298828}\n",
      "{'ner': 33.08907747268677}\n",
      "{'ner': 31.74453830718994}\n",
      "{'ner': 31.57049548625946}\n",
      "{'ner': 30.441071689128876}\n",
      "{'ner': 33.05082646012306}\n",
      "{'ner': 33.48699629306793}\n",
      "{'ner': 34.50110548734665}\n",
      "{'ner': 34.516260266304016}\n",
      "{'ner': 32.75094082951546}\n"
     ]
    }
   ],
   "source": [
    "# Lecture des données annotées pour l'entraînement du modèle\n",
    "with open('train_data.json', 'r', encoding='utf-8') as file:\n",
    "    training_data = json.load(file)\n",
    "\n",
    "# Entraînement du modèle SpaCy\n",
    "nlp = spacy.blank(\"fr\")\n",
    "ner = nlp.add_pipe(\"ner\", last=True)\n",
    "\n",
    "# Ajout des labels\n",
    "ner.add_label(\"PER\")\n",
    "ner.add_label(\"EXP\")\n",
    "ner.add_label(\"DATE\")\n",
    "# Ajoute d'autres labels nécessaires (PHONE, EMAIL, etc.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Création des exemples pour l'entraînement du modèle\n",
    "examples = []\n",
    "for data in training_data:\n",
    "    text = data[\"text\"]\n",
    "    entities = []\n",
    "    for entity in data[\"entities\"]:\n",
    "        start, end, label = entity[\"start\"], entity[\"end\"], entity[\"label\"]\n",
    "        entities.append((start, end, label))\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), {\"entities\": entities}))\n",
    "\n",
    "# Entraînement du modèle\n",
    "nlp.initialize(lambda: examples)\n",
    "for i in range(10):  # Nombre d'itérations d'entraînement\n",
    "    losses = {}\n",
    "    nlp.update(examples, drop=0.5, losses=losses)\n",
    "    print(losses)\n",
    "\n",
    "# Sauvegarde du modèle entraîné\n",
    "nlp.to_disk(\"modele_cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test du modele d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle SpaCy entraîné\n",
    "nlp_loaded = spacy.load(\"modele_cv\")\n",
    "\n",
    "# Extraction des informations du nouveau CV\n",
    "pdf_path = \"CV-14.pdf\"\n",
    "cv_text = extract_text_from_pdf(pdf_path)\n",
    "doc = nlp_loaded(cv_text)\n",
    "\n",
    "# Affichage des entités extraites du CV\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text extraction mail et telephone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numéros de téléphone trouvés :\n",
      "['0485435365']\n",
      "\n",
      "Adresses e-mail trouvées :\n",
      "['nom@gmail.com']\n",
      "\n",
      "Langues parlées :\n",
      "['Français', 'Anglais']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_rangesss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLangues parlées :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(extract_languages(extracted_text))\n\u001b[1;32m---> 12\u001b[0m dates \u001b[38;5;241m=\u001b[39m \u001b[43mextract_date_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlages de dates trouvées :\u001b[39m\u001b[38;5;124m\"\u001b[39m, dates)\n",
      "Cell \u001b[1;32mIn[113], line 40\u001b[0m, in \u001b[0;36mextract_date_ranges\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     38\u001b[0m matches_underscore_witout_space \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(regex_underscore_witout_space, text)\n\u001b[0;32m     39\u001b[0m matches_dash_witout_space \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(regex_dash_witout_space, text)\n\u001b[1;32m---> 40\u001b[0m matches_date_rangesss \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[43mdate_rangesss\u001b[49m, text)\n\u001b[0;32m     41\u001b[0m matches_date_rangeM \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(date_rangeM, text)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Ajout des résultats des deux expressions régulières dans un seul tableau\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date_rangesss' is not defined"
     ]
    }
   ],
   "source": [
    "phone_numbers = extract_phone_numbers(extracted_text)\n",
    "emails = extract_emails(extracted_text)\n",
    "\n",
    "print(\"Numéros de téléphone trouvés :\")\n",
    "print(phone_numbers)\n",
    "print(\"\\nAdresses e-mail trouvées :\")\n",
    "print(emails)\n",
    "print(\"\\nLangues parlées :\")\n",
    "print(extract_languages(extracted_text))\n",
    "\n",
    "\n",
    "dates = extract_date_ranges(extracted_text)\n",
    "print(\"Plages de dates trouvées :\", dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
